<body style="margin: 0 auto;width: 70%"> 
    <p class="Research-Text" style="margin-left: 40px; margin-right: 40px;"> 
        This work undertakes studies to evaluate Interpretability
        Methods for Time-Series Deep Learning. Sensitivity analysis assesses how input changes affect the output, constituting
        a key component of interpretation. Among the post-hoc interpretation methods such as back-propagation, perturbation,
        and approximation, my work will investigate perturbationbased sensitivity Analysis methods on modern Transformer
        models to benchmark their performances. Specifically, my
        work intends to answer three research questions: 1) Do different sensitivity analysis methods yield comparable outputs
        and attribute importance rankings? 2) Using the same sensitivity analysis method, do different Deep Learning models
        impact the output of the sensitivity analysis? 3) How well do
        the results from sensitivity analysis methods align with the
        ground truth?
      </p>
      <h2 class="research-topic" style="margin-left: 40px; margin-right: 40px;"> My Contributions</h2>
      <p class="Research-Text" style="margin-left: 40px; margin-right: 40px;"> 
      This research statement is original by the author and was accepted for presentation at AAAI-24. 
      </p>
    </body>